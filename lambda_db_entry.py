import json
import os
import urllib.request
#import re
import boto3
import decimal

from datetime import datetime
from boto3 import resource
from boto3.dynamodb.conditions import Key, Attr
from botocore.exceptions import ClientError

BUCKET_NAME = os.environ['BUCKET_NAME']
TABLE_NAME = os.environ['TABLE_NAME']

# define boto3 resources and clients

#table = dynamodb.Table(TABLE_NAME)
transcribe = boto3.client('transcribe')

def get_matching_s3_objects(bucket, prefix="", suffix=""):
    """
    Generate objects in an S3 bucket.

    :param bucket: Name of the S3 bucket.
    :param prefix: Only fetch objects whose key starts with
        this prefix (optional).
    :param suffix: Only fetch objects whose keys end with
        this suffix (optional).

    Credit: Alex Chan
    Source: https://alexwlchan.net/2019/07/listing-s3-keys/
    """
    s3 = boto3.client("s3")
    paginator = s3.get_paginator("list_objects_v2")

    kwargs = {'Bucket': bucket}

    # We can pass the prefix directly to the S3 API.  If the user has passed
    # a tuple or list of prefixes, we go through them one by one.
    if isinstance(prefix, str):
        prefixes = (prefix, )
    else:
        prefixes = prefix

    for key_prefix in prefixes:
        kwargs["Prefix"] = key_prefix

        for page in paginator.paginate(**kwargs):
            try:
                contents = page["Contents"]
            except KeyError:
                return

            for obj in contents:
                key = obj["Key"]
                if key.endswith(suffix):
                    yield obj


def get_matching_s3_keys(bucket, prefix="", suffix=""):
    """
    Generate the keys in an S3 bucket.

    :param bucket: Name of the S3 bucket.
    :param prefix: Only fetch keys that start with this prefix (optional).
    :param suffix: Only fetch keys that end with this suffix (optional).

    Credit: Alex Chan
    Source: https://alexwlchan.net/2019/07/listing-s3-keys/

    Usage example: res = get_matching_s3_keys(bucket = BUCKET_NAME, prefix = "source/", suffix = ".mp3")
    """
    for obj in get_matching_s3_objects(bucket, prefix, suffix):
        yield obj["Key"]

def decimal_default(obj):
    if isinstance(obj, decimal.Decimal):
        return int(obj)
    raise TypeError

def create_summary(text, n_sentences=4):
    #  https://stackoverflow.com/a/17124446
    res = ' '.join(re.split(r'(?<=[.:;])\s', text)[:n_sentences])
    res2 = res + '...' + '\n\n' + 'Listen to the rest of the snippet to find out more!'
    return res2

def get_table_metadata(table_name):
    """
    Get some metadata about chosen table.
    """
    table = dynamodb_resource.Table(table_name)

    return {
        'num_items': table.item_count,
        'primary_key_name': table.key_schema[0],
        'status': table.table_status,
        'bytes_size': table.table_size_bytes,
        'global_secondary_indices': table.global_secondary_indexes
    }

def add_item(table_name, col_dict):
    """
    Add one item (row) to table. col_dict is a dictionary {col_name: value}.
    """
    dynamodb_resource = resource('dynamodb', region_name='us-east-1')
    table = dynamodb_resource.Table(table_name)
    response = table.put_item(Item=col_dict)

    return response

def lambda_handler(event, context):

    # job_name comes from event json (use this as episode_id in table)
    job_name = event['detail']['TranscriptionJobName']
    job = transcribe.get_transcription_job(TranscriptionJobName=job_name)

    source_mp3_url = job['TranscriptionJob']['Media']['MediaFileUri']

    uri = job['TranscriptionJob']['Transcript']['TranscriptFileUri']
    content = urllib.request.urlopen(uri).read().decode('UTF-8')

    # extract transcript contents
    # for debugging
    print(json.dumps(content))
    data = json.loads(content)
    text = data['results']['transcripts'][0]['transcript']

    # determine how many episodes are in s3 bucket in order to define episode index
    res = get_matching_s3_keys(bucket = BUCKET_NAME, prefix = "source/", suffix = ".mp3")
    n_files = n_files = len(list(res))

    # define episode metadata for database entry
    episode_int = n_files
    episode_index = str(episode_int).zfill(3)
    episode_title = "Residual Snippet #" + episode_index
    sum_header = "Residual Snippet {episode_index} transcript auto-generated by Amazon Transcription service. Be adviced it may not be 100 percent accurate!".format(episode_index = episode_index)
    episode_summary = '\n\n'.join(sum_header, text)
    episode_timestamp = time.strftime("%Y-%m-%d_%H-%M")

    # assemble dictionary for entry
    episode_dict = {
        'episode_id': job_name,
        'episode_int': episode_int,
        'episode_index': episode_index,
        'episode_title': episode_title,
        'episode_summary': episode_summary,
        'episode_timestamp': episode_timestamp,
        'episode_url': source_mp3_url
    }

    dbsuccess = add_item(table_name = TABLE_NAME, col_dict = episode_dict)

    if dbsuccess:
        print("added entry to dynamodb")

    






    